{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bovw.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "EH1S4poVXRP9",
        "colab_type": "code",
        "outputId": "0f756d90-78c8-4421-9a03-e1789feaacd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NF_QMrHlXXiQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip uninstall scikit-image\n",
        "# !pip install scikit-image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ha6sdED1XXhS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ReadData():\n",
        "    data = []\n",
        "    label = []\n",
        "    for i in range(1, 6):\n",
        "        with open(\"Colab Notebooks/Data/data_batch_\" + str(i), 'rb') as fo:\n",
        "            dict = pickle.load(fo, encoding='bytes')\n",
        "            data.append(dict[b'data'])\n",
        "            label.append(dict[b'labels'])\n",
        "\n",
        "    for i in range(1, 5):\n",
        "        data[0] = np.concatenate((data[0], data[i]), axis = 0)\n",
        "        label[0] = np.concatenate((label[0], label[i]), axis = 0)\n",
        "\n",
        "    test = []\n",
        "    test_label = []\n",
        "    with open(\"Colab Notebooks/Data/test_batch\", 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "        test.append(dict[b'data'])\n",
        "        test_label.append(dict[b'labels'])\n",
        "\n",
        "    data = np.asarray(data[0])\n",
        "    label = np.asarray(label[0])\n",
        "    test = np.asarray(test[0])\n",
        "    test_label = np.asarray(test_label[0])\n",
        "    return data, label, test, test_label "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLqdAvDeXuTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def HOG_features(x_train):\n",
        "    fds = []\n",
        "    for i in range(x_train.shape[0]):\n",
        "        Image = np.reshape(x_train[i], (32, 32, 3))\n",
        "        # cv2.imwrite(\"./Q4-output/original.png\", Image)\n",
        "        # fd, _ = hog(Image, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(1, 1), visualize=True, multichannel=True, block_norm=\"L2-Hys\")\n",
        "        fd, _ = hog(Image, visualize=True, multichannel=True, block_norm=\"L2-Hys\")\n",
        "\n",
        "        fds.extend(fd)\n",
        "\n",
        "    fds = np.asarray(fds)\n",
        "    fds = np.reshape(fds, (fds.shape[0], 1))\n",
        "    print(\"Fds.shape\", fds.shape)\n",
        "    return fds\n",
        "\n",
        "def LBP_features(x_train, num_points = 24, radius = 3):\n",
        "    fds = []\n",
        "    for i in range(x_train.shape[0]):\n",
        "        Image = np.reshape(x_train[i], (32, 32, 3))\n",
        "        Image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
        "        lbp = local_binary_pattern(Image, num_points, radius, method=\"uniform\")\n",
        "        # cv2.imwrite(\"./Q4-output/lbp1.png\", lbp)\n",
        "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
        "        hist = hist.astype(dtype=np.float)\n",
        "        hist /= np.sum(hist)\n",
        "        fds.extend(hist)\n",
        "    \n",
        "    fds = np.asarray(fds)\n",
        "    fds = np.reshape(fds, (fds.shape[0], 1))\n",
        "    print(\"Fds.shape\", fds.shape)\n",
        "    return fds\n",
        "\n",
        "def getHistorgram(kmeans, x_data, num_points = 24, radius = 3, hog_flag=True):\n",
        "    features = []\n",
        "    hist_size = len(kmeans.cluster_centers_)\n",
        "    # print(\"Clusters:\", hist_size)\n",
        "    for i in range(x_data.shape[0]):\n",
        "        Image = np.reshape(x_data[i], (32, 32, 3))\n",
        "        histogram = np.zeros((hist_size, ))\n",
        "        if hog_flag:\n",
        "            # fd, _ = hog(Image, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(1, 1), visualize=True, multichannel=True, block_norm=\"L2-Hys\")\n",
        "            fd, _ = hog(Image, visualize=True, multichannel=True, block_norm=\"L2-Hys\")\n",
        "            norm = np.size(fd)\n",
        "            fd = np.reshape(fd, (fd.shape[0], 1))\n",
        "            histogram[kmeans.predict(fd)] += 1/norm\n",
        "        else:\n",
        "            Image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
        "            lbp = local_binary_pattern(Image, num_points, radius, method=\"uniform\")  # cv2.imwrite(\"./Q4-output/lbp1.png\", lbp)\n",
        "            hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
        "            hist = hist.astype(dtype=np.float)\n",
        "            hist /= np.sum(hist)\n",
        "            hist = np.reshape(hist, (hist.shape[0], 1))\n",
        "            histogram[kmeans.predict(hist)] += 1\n",
        "        features.append(histogram)\n",
        "    features = np.asarray(features)\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dueFIWpdchCG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_Train, Y_Train, X_Test, Y_Test = ReadData()\n",
        "X_Train = X_Train[:10000]\n",
        "Y_Train = Y_Train[:10000]\n",
        "X_Test = X_Test[:1000]\n",
        "Y_Test = Y_Test[:1000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dwEBksQ_fWGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a460ae7d-fd02-4a36-f720-109dd5faed22"
      },
      "cell_type": "code",
      "source": [
        "fd_list = HOG_features(X_Train)\n",
        "# fd_list = LBP_features(X_Train)\n",
        "hog_flag = True\n",
        "print(\"------------------Features Collected-----------------\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fds.shape (3240000, 1)\n",
            "------------------Features Collected-----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wA6rF0avXyTN",
        "colab_type": "code",
        "outputId": "55bf233a-63b0-481a-dbed-7741b46a9f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "kmeans = KMeans(n_clusters = 150)\n",
        "kmeans.fit(fd_list)\n",
        "print(\"------------------K-Mean Clutering Done--------------\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------K-Mean Clutering Done--------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lOXHaQOX4vj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle.dump(kmeans, open(\"Colab Notebooks/Data/kmeans.sav\", 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVmfC4Zlb5EE",
        "colab_type": "code",
        "outputId": "a15ba3c7-244d-435c-bc89-4fc3cfdca481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "nx_train = getHistorgram(kmeans, X_Train, hog_flag=hog_flag)\n",
        "print(\"nx_train.shape\", nx_train.shape)\n",
        "nx_test = getHistorgram(kmeans, X_Test, hog_flag=hog_flag)\n",
        "print(\"nx_test.shape\", nx_test.shape)\n",
        "print(\"------------------Histogram Features-----------------\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nx_train.shape (10000, 150)\n",
            "nx_test.shape (1000, 150)\n",
            "------------------Histogram Features-----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hq_n9_mGdNjk",
        "colab_type": "code",
        "outputId": "baf36e08-177b-495f-f29e-bd6c7ff61a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"------------------Training SVM-----------------------\")\n",
        "clf = SVC(gamma='scale', decision_function_shape='ovo')\n",
        "clf.fit(nx_train, Y_Train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------Training SVM-----------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
              "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "McKCDQRrdROa",
        "colab_type": "code",
        "outputId": "1d25db7b-7efc-47f6-ba54-88523c947b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"------------------Predicting Score-------------------\")\n",
        "Accuracy = clf.score(nx_test, Y_Test)\n",
        "\n",
        "print(\"Acc\", Accuracy*100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------Predicting Score-------------------\n",
            "Acc 19.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fhBWTGOHdb6R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}